input {
  stdin {}
  dead_letter_queue {
    path => "/tmp/dlq"
    # this is the last bit of dlq_path below
    pipeline_id => "main"
    # this is so we can identify the source of the event in the filter
    add_field => { "source" => "dlq_input" }
  }
}

filter {
  # get the ID from the input, but only if it's NOT from the dead letter queue
  # this is the event that will fail, because it comes with an invalid operation
  if [source] != "dlq_input" {
    csv {
      separator => ","
      skip_header => true
      # we need the "id" and "operation" fields in the schema for now
      columns => ["operation", "id"]
    }
  } else {
    # if it's from the dead letter queue, remove the source field and fix the operation
    # this way it goes into Vespa as a put request and we can verify that the DLQ worked correctly
    mutate {
        remove_field => ["source"]
        replace => { "operation" => "put" }
    }
  }

  # remove fields that are not needed
  mutate {
    remove_field => ["@timestamp", "@version", "event", "host", "log", "message"]
  }
}

output {
  stdout { codec => rubydebug }
  vespa_feed {
    vespa_url => "http://localhost:8080"
    operation => "%{operation}"
    remove_operation => true
    # write failed events to the dead letter queue  
    enable_dlq => true
    dlq_path => "/tmp/dlq/main"
    # flush every 50ms, to make sure the file is populated quickly
    flush_interval => 50
  }
} 